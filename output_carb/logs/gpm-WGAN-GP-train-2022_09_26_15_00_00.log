[INFO] 2022-09-26 15:00:00 > Run name : gpm-WGAN-GP-train-2022_09_26_15_00_00
[INFO] 2022-09-26 15:00:00 > cfgs.DATA =
[INFO] 2022-09-26 15:00:00 > {
  "name": "gpm",
  "img_size": 64,
  "num_classes": 1,
  "img_channels": 3,
  "num_dims": 2
}
[INFO] 2022-09-26 15:00:00 > cfgs.MODEL =
[INFO] 2022-09-26 15:00:00 > {
  "backbone": "resnet",
  "g_cond_mtd": "W/O",
  "d_cond_mtd": "W/O",
  "aux_cls_type": "W/O",
  "normalize_d_embed": false,
  "d_embed_dim": "N/A",
  "apply_g_sn": false,
  "apply_d_sn": false,
  "g_act_fn": "ReLU",
  "d_act_fn": "ReLU",
  "apply_attn": false,
  "attn_g_loc": [
    "N/A"
  ],
  "attn_d_loc": [
    "N/A"
  ],
  "z_prior": "gaussian",
  "z_dim": 16,
  "w_dim": "N/A",
  "g_shared_dim": "N/A",
  "g_conv_dim": 2,
  "d_conv_dim": 2,
  "g_depth": "N/A",
  "d_depth": "N/A",
  "apply_g_ema": false,
  "g_ema_decay": "N/A",
  "g_ema_start": "N/A",
  "g_init": "ortho",
  "d_init": "ortho"
}
[INFO] 2022-09-26 15:00:00 > cfgs.LOSS =
[INFO] 2022-09-26 15:00:00 > {
  "adv_loss": "wasserstein",
  "cond_lambda": "N/A",
  "tac_gen_lambda": "N/A",
  "tac_dis_lambda": "N/A",
  "mh_lambda": "N/A",
  "apply_fm": false,
  "fm_lambda": "N/A",
  "apply_r1_reg": false,
  "r1_lambda": "N/A",
  "m_p": "N/A",
  "temperature": "N/A",
  "apply_wc": false,
  "wc_bound": "N/A",
  "apply_gp": true,
  "gp_lambda": 10.0,
  "apply_dra": false,
  "dra_labmda": "N/A",
  "apply_maxgp": false,
  "maxgp_lambda": "N/A",
  "apply_cr": false,
  "cr_lambda": "N/A",
  "apply_bcr": false,
  "real_lambda": "N/A",
  "fake_lambda": "N/A",
  "apply_zcr": false,
  "radius": "N/A",
  "g_lambda": "N/A",
  "d_lambda": "N/A",
  "apply_lo": false,
  "lo_alpha": "N/A",
  "lo_beta": "N/A",
  "lo_rate": "N/A",
  "lo_lambda": "N/A",
  "lo_steps4train": "N/A",
  "lo_steps4eval": "N/A",
  "apply_topk": false,
  "topk_gamma": "N/A",
  "topk_nu": "N/A"
}
[INFO] 2022-09-26 15:00:00 > cfgs.OPTIMIZATION =
[INFO] 2022-09-26 15:00:00 > {
  "type_": "Adam",
  "batch_size": 128,
  "acml_steps": 1,
  "g_lr": 0.0002,
  "d_lr": 0.0002,
  "g_weight_decay": 0.0,
  "d_weight_decay": 0.0,
  "momentum": "N/A",
  "nesterov": "N/A",
  "alpha": "N/A",
  "beta1": 0.5,
  "beta2": 0.999,
  "g_updates_per_step": 1,
  "d_updates_per_step": 2,
  "total_steps": 30000,
  "world_size": 2
}
[INFO] 2022-09-26 15:00:00 > cfgs.PRE =
[INFO] 2022-09-26 15:00:00 > {
  "apply_rflip": true,
  "crop_long_edge": true,
  "resize_size": 64
}
[INFO] 2022-09-26 15:00:00 > cfgs.AUG =
[INFO] 2022-09-26 15:00:00 > {
  "apply_diffaug": false,
  "apply_ada": false,
  "cr_aug_type": "W/O",
  "bcr_aug_type": "W/O",
  "diffaug_type": "W/O",
  "ada_aug_type": "W/O",
  "ada_initial_augment_p": "N/A",
  "ada_target": "N/A",
  "ada_kimg": "N/A",
  "ada_interval": "N/A"
}
[INFO] 2022-09-26 15:00:00 > cfgs.RUN =
[INFO] 2022-09-26 15:00:00 > {
  "entity": null,
  "project": "gpm_carb",
  "cfg_file": "src/configs/GPM_carb/WGAN-GP.yaml",
  "data_dir": "data/gpm_carb_256/",
  "save_dir": "./output_carb/",
  "ckpt_dir": null,
  "load_best": false,
  "seed": 1103,
  "distributed_data_parallel": false,
  "backend": "nccl",
  "total_nodes": 1,
  "current_node": 0,
  "num_workers": 8,
  "synchronized_bn": false,
  "mixed_precision": false,
  "truncation_factor": -1.0,
  "truncation_cutoff": null,
  "batch_statistics": false,
  "standing_statistics": false,
  "standing_max_batch": -1,
  "standing_step": -1,
  "freezeD": -1,
  "langevin_sampling": false,
  "langevin_rate": -1,
  "langevin_noise_std": -1,
  "langevin_decay": -1,
  "langevin_decay_steps": -1,
  "langevin_steps": -1,
  "train": true,
  "load_train_hdf5": false,
  "load_data_in_memory": false,
  "eval": false,
  "save_fake_images": true,
  "vis_fake_images": false,
  "k_nearest_neighbor": false,
  "interpolation": false,
  "frequency_analysis": false,
  "tsne_analysis": false,
  "intra_class_fid": false,
  "GAN_train": false,
  "GAN_test": false,
  "resume_classifier_train": false,
  "semantic_factorization": false,
  "num_semantic_axis": -1,
  "maximum_variations": -1,
  "print_every": 100,
  "save_every": 100,
  "eval_backbone": "Inception_V3",
  "ref_dataset": "train"
}
[INFO] 2022-09-26 15:00:00 > cfgs.STYLEGAN2 =
[INFO] 2022-09-26 15:00:00 > {
  "cond_type": [
    "PD",
    "SPD",
    "2C",
    "D2DCE"
  ],
  "g_reg_interval": "N/A",
  "d_reg_interval": "N/A",
  "mapping_network": "N/A",
  "style_mixing_p": "N/A",
  "g_ema_kimg": "N/A",
  "g_ema_rampup": "N/A",
  "apply_pl_reg": false,
  "pl_weight": "N/A",
  "d_architecture": "N/A",
  "d_epilogue_mbstd_group_size": "N/A"
}
[INFO] 2022-09-26 15:00:00 > Load gpm train dataset.
[INFO] 2022-09-26 15:00:00 > Train dataset size: 1750
[INFO] 2022-09-26 15:00:00 > Build a Generative Adversarial Network.
[INFO] 2022-09-26 15:00:00 > Modules are located on './src/models.resnet'.
[INFO] 2022-09-26 15:00:03 > Number of parameters: 18895
[INFO] 2022-09-26 15:00:03 > Generator(
  (linear0): Linear(in_features=16, out_features=512, bias=True)
  (blocks): ModuleList(
    (0): ModuleList(
      (0): GenBlock(
        (bn1): BatchNorm2d(32, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)
        (bn2): BatchNorm2d(16, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)
        (activation): ReLU(inplace=True)
        (conv2d0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))
        (conv2d1): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (conv2d2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (1): ModuleList(
      (0): GenBlock(
        (bn1): BatchNorm2d(16, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)
        (bn2): BatchNorm2d(8, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)
        (activation): ReLU(inplace=True)
        (conv2d0): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1))
        (conv2d1): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (conv2d2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (2): ModuleList(
      (0): GenBlock(
        (bn1): BatchNorm2d(8, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)
        (bn2): BatchNorm2d(4, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)
        (activation): ReLU(inplace=True)
        (conv2d0): Conv2d(8, 4, kernel_size=(1, 1), stride=(1, 1))
        (conv2d1): Conv2d(8, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (conv2d2): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (3): ModuleList(
      (0): GenBlock(
        (bn1): BatchNorm2d(4, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)
        (bn2): BatchNorm2d(2, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)
        (activation): ReLU(inplace=True)
        (conv2d0): Conv2d(4, 2, kernel_size=(1, 1), stride=(1, 1))
        (conv2d1): Conv2d(4, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (conv2d2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
  )
  (bn4): BatchNorm2d(2, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)
  (activation): ReLU(inplace=True)
  (conv2d5): Conv2d(2, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (tanh): Tanh()
)
[INFO] 2022-09-26 15:00:03 > Number of parameters: 19605
[INFO] 2022-09-26 15:00:03 > Discriminator(
  (blocks): ModuleList(
    (0): ModuleList(
      (0): DiscOptBlock(
        (conv2d0): Conv2d(3, 2, kernel_size=(1, 1), stride=(1, 1))
        (conv2d1): Conv2d(3, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (conv2d2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (bn0): BatchNorm2d(3, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)
        (bn1): BatchNorm2d(2, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)
        (activation): ReLU(inplace=True)
        (average_pooling): AvgPool2d(kernel_size=2, stride=2, padding=0)
      )
    )
    (1): ModuleList(
      (0): DiscBlock(
        (activation): ReLU(inplace=True)
        (conv2d0): Conv2d(2, 4, kernel_size=(1, 1), stride=(1, 1))
        (bn0): BatchNorm2d(2, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)
        (conv2d1): Conv2d(2, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (conv2d2): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (bn1): BatchNorm2d(2, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)
        (bn2): BatchNorm2d(4, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)
        (average_pooling): AvgPool2d(kernel_size=2, stride=2, padding=0)
      )
    )
    (2): ModuleList(
      (0): DiscBlock(
        (activation): ReLU(inplace=True)
        (conv2d0): Conv2d(4, 8, kernel_size=(1, 1), stride=(1, 1))
        (bn0): BatchNorm2d(4, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)
        (conv2d1): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (conv2d2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (bn1): BatchNorm2d(4, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)
        (bn2): BatchNorm2d(8, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)
        (average_pooling): AvgPool2d(kernel_size=2, stride=2, padding=0)
      )
    )
    (3): ModuleList(
      (0): DiscBlock(
        (activation): ReLU(inplace=True)
        (conv2d0): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))
        (bn0): BatchNorm2d(8, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)
        (conv2d1): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (conv2d2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (bn1): BatchNorm2d(8, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)
        (bn2): BatchNorm2d(16, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)
        (average_pooling): AvgPool2d(kernel_size=2, stride=2, padding=0)
      )
    )
    (4): ModuleList(
      (0): DiscBlock(
        (activation): ReLU(inplace=True)
        (conv2d0): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))
        (bn0): BatchNorm2d(16, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)
        (conv2d1): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (conv2d2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (bn1): BatchNorm2d(16, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)
        (bn2): BatchNorm2d(32, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)
        (average_pooling): AvgPool2d(kernel_size=2, stride=2, padding=0)
      )
    )
  )
  (activation): ReLU(inplace=True)
  (linear1): Linear(in_features=32, out_features=1, bias=True)
)
[INFO] 2022-09-26 15:00:07 > Start training!
[INFO] 2022-09-26 15:01:00 > Step:    100 Progress: 0.3% Elapsed: 0:00:53 Gen_loss: 44.92 Dis_loss: -78.09 Cls_loss: N/A Topk:  N/A ada_p: N/A 
[INFO] 2022-09-26 15:01:00 > Visualize (num_rows x 8) fake image canvans.
[INFO] 2022-09-26 15:01:00 > Save image canvas to ./output_carb/figures/gpm-WGAN-GP-train-2022_09_26_15_00_00/generated_canvas_100.png
[INFO] 2022-09-26 15:01:01 > Save model to ./output_carb/checkpoints/gpm-WGAN-GP-train-2022_09_26_15_00_00
[INFO] 2022-09-26 15:01:51 > Step:    200 Progress: 0.7% Elapsed: 0:01:43 Gen_loss: 114.0 Dis_loss: -248.6 Cls_loss: N/A Topk:  N/A ada_p: N/A 
[INFO] 2022-09-26 15:01:51 > Visualize (num_rows x 8) fake image canvans.
[INFO] 2022-09-26 15:01:51 > Save image canvas to ./output_carb/figures/gpm-WGAN-GP-train-2022_09_26_15_00_00/generated_canvas_200.png
[INFO] 2022-09-26 15:01:51 > Save model to ./output_carb/checkpoints/gpm-WGAN-GP-train-2022_09_26_15_00_00
[INFO] 2022-09-26 15:02:39 > Step:    300 Progress: 1.0% Elapsed: 0:02:32 Gen_loss: 293.8 Dis_loss: -709.1 Cls_loss: N/A Topk:  N/A ada_p: N/A 
[INFO] 2022-09-26 15:02:39 > Visualize (num_rows x 8) fake image canvans.
[INFO] 2022-09-26 15:02:39 > Save image canvas to ./output_carb/figures/gpm-WGAN-GP-train-2022_09_26_15_00_00/generated_canvas_300.png
[INFO] 2022-09-26 15:02:40 > Save model to ./output_carb/checkpoints/gpm-WGAN-GP-train-2022_09_26_15_00_00
